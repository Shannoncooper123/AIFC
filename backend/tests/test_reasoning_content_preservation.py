"""
æµ‹è¯•æ·±åº¦æ€è€ƒå†…å®¹ï¼ˆreasoning_contentï¼‰åœ¨ Agent Tool è°ƒç”¨å¾ªç¯ä¸­çš„ä¿ç•™ä¸ä¼ é€’

æµ‹è¯•ç›®æ ‡ï¼š
1. éªŒè¯ä½¿ç”¨ç«å±±å¼•æ“ Responses API æ—¶ï¼Œreasoning å†…å®¹æ˜¯å¦è¢«æ­£ç¡®è§£æåˆ° AIMessage
2. éªŒè¯åœ¨å¤šè½® tool è°ƒç”¨ä¸­ï¼Œä¹‹å‰çš„ reasoning å†…å®¹æ˜¯å¦è¢«ä¼ é€’ç»™ä¸‹ä¸€è½®è¯·æ±‚
3. éªŒè¯ LangChain çš„ _construct_responses_api_input æ˜¯å¦æ­£ç¡®å¤„ç† reasoning blocks

è¿è¡Œæ–¹å¼ï¼š
    cd /Users/bytedance/Desktop/crypto_agentx/backend
    source .venv/bin/activate
    python tests/test_reasoning_content_preservation.py

ç¯å¢ƒå˜é‡è¦æ±‚ï¼ˆ.envï¼‰ï¼š
    AGENT_MODEL=doubao-seed-1-8-251228  # æˆ–å…¶ä»–æ”¯æŒæ·±åº¦æ€è€ƒçš„æ¨¡å‹
    AGENT_BASE_URL=https://ark.cn-beijing.volces.com/api/v3
    AGENT_API_KEY=your_ark_api_key
"""

import os
import sys
from typing import Any
from unittest.mock import patch

from dotenv import load_dotenv

load_dotenv()

from langchain.agents import create_agent
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, ToolMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI


class ReasoningInspectorCallback(BaseCallbackHandler):
    """å›è°ƒå¤„ç†å™¨ï¼šæ£€æŸ¥æ¯æ¬¡ LLM è°ƒç”¨çš„è¾“å…¥è¾“å‡ºä¸­çš„ reasoning å†…å®¹"""
    
    def __init__(self):
        self.call_count = 0
        self.reasoning_found_in_responses: list[dict] = []
        self.reasoning_found_in_requests: list[dict] = []
        self.all_ai_messages: list[AIMessage] = []
    
    def on_llm_start(self, serialized: dict, prompts: list[str], **kwargs):
        self.call_count += 1
        messages = kwargs.get("invocation_params", {}).get("messages", [])
        
        print(f"\n{'='*60}")
        print(f"ğŸ” LLM è°ƒç”¨ #{self.call_count} - æ£€æŸ¥è¾“å…¥æ¶ˆæ¯ä¸­çš„ reasoning")
        print(f"{'='*60}")
        
        reasoning_in_request = []
        for i, msg in enumerate(messages):
            if isinstance(msg, dict):
                role = msg.get("role", "")
                if role == "assistant":
                    content = msg.get("content", [])
                    if isinstance(content, list):
                        for block in content:
                            if isinstance(block, dict) and block.get("type") in ("reasoning", "output_text", "text"):
                                block_type = block.get("type")
                                if block_type == "reasoning":
                                    reasoning_in_request.append({
                                        "message_index": i,
                                        "reasoning_block": block
                                    })
                                    print(f"  âœ… å‘ç° reasoning block åœ¨æ¶ˆæ¯ #{i}:")
                                    summary = block.get("summary", [])
                                    if summary:
                                        for s in summary[:2]:
                                            text = s.get("text", "")[:100]
                                            print(f"     - {text}...")
            elif isinstance(msg, dict) and msg.get("type") == "reasoning":
                reasoning_in_request.append({
                    "message_index": i,
                    "reasoning_block": msg
                })
                print(f"  âœ… å‘ç°ç‹¬ç«‹ reasoning item åœ¨ä½ç½® #{i}")
        
        if not reasoning_in_request:
            print("  âš ï¸  è¾“å…¥æ¶ˆæ¯ä¸­æœªå‘ç° reasoning blocksï¼ˆæ³¨æ„ï¼šè¿™é‡Œæ£€æŸ¥çš„æ˜¯ LangChain å†…éƒ¨æ ¼å¼ï¼‰")
        
        self.reasoning_found_in_requests.append({
            "call_number": self.call_count,
            "reasoning_blocks": reasoning_in_request
        })
    
    def on_llm_end(self, response, **kwargs):
        print(f"\nğŸ“¤ LLM è°ƒç”¨ #{self.call_count} - æ£€æŸ¥è¾“å‡ºå“åº”ä¸­çš„ reasoning")
        
        generations = response.generations if hasattr(response, "generations") else []
        for gen_list in generations:
            for gen in gen_list:
                if hasattr(gen, "message") and isinstance(gen.message, AIMessage):
                    ai_msg = gen.message
                    self.all_ai_messages.append(ai_msg)
                    
                    reasoning_found = self._extract_reasoning_from_message(ai_msg)
                    if reasoning_found:
                        self.reasoning_found_in_responses.append({
                            "call_number": self.call_count,
                            "reasoning": reasoning_found
                        })
                        print(f"  âœ… å“åº”ä¸­åŒ…å« reasoning å†…å®¹:")
                        for r in reasoning_found[:2]:
                            print(f"     - {r[:100]}...")
                    else:
                        print("  âš ï¸  å“åº”ä¸­æœªå‘ç° reasoning å†…å®¹")
    
    def _extract_reasoning_from_message(self, msg: AIMessage) -> list[str]:
        """ä» AIMessage ä¸­æå– reasoning å†…å®¹"""
        reasoning_texts = []
        
        if "reasoning" in msg.additional_kwargs:
            reasoning = msg.additional_kwargs["reasoning"]
            if isinstance(reasoning, dict):
                summary = reasoning.get("summary", [])
                for s in summary:
                    if isinstance(s, dict) and "text" in s:
                        reasoning_texts.append(s["text"])
                    elif isinstance(s, str):
                        reasoning_texts.append(s)
        
        if isinstance(msg.content, list):
            for block in msg.content:
                if isinstance(block, dict) and block.get("type") == "reasoning":
                    summary = block.get("summary", [])
                    for s in summary:
                        if isinstance(s, dict) and "text" in s:
                            reasoning_texts.append(s["text"])
                        elif isinstance(s, str):
                            reasoning_texts.append(s)
        
        return reasoning_texts


call_counter = {"count": 0}


@tool("calculate_fibonacci")
def calculate_fibonacci(n: int) -> str:
    """è®¡ç®—ç¬¬ n ä¸ªæ–æ³¢é‚£å¥‘æ•°
    
    Args:
        n: è¦è®¡ç®—çš„æ–æ³¢é‚£å¥‘æ•°çš„ä½ç½®ï¼ˆä» 1 å¼€å§‹ï¼‰
    
    Returns:
        è®¡ç®—ç»“æœçš„æè¿°
    """
    call_counter["count"] += 1
    print(f"\nğŸ”§ Tool è¢«è°ƒç”¨: calculate_fibonacci(n={n}) - ç¬¬ {call_counter['count']} æ¬¡è°ƒç”¨")
    
    if n <= 0:
        return "é”™è¯¯ï¼šn å¿…é¡»æ˜¯æ­£æ•´æ•°"
    if n == 1 or n == 2:
        return f"ç¬¬ {n} ä¸ªæ–æ³¢é‚£å¥‘æ•°æ˜¯ 1"
    
    a, b = 1, 1
    for _ in range(n - 2):
        a, b = b, a + b
    
    return f"ç¬¬ {n} ä¸ªæ–æ³¢é‚£å¥‘æ•°æ˜¯ {b}"


@tool("get_current_time")
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´
    
    Returns:
        å½“å‰æ—¶é—´çš„å­—ç¬¦ä¸²è¡¨ç¤º
    """
    call_counter["count"] += 1
    from datetime import datetime
    print(f"\nğŸ”§ Tool è¢«è°ƒç”¨: get_current_time() - ç¬¬ {call_counter['count']} æ¬¡è°ƒç”¨")
    return f"å½“å‰æ—¶é—´æ˜¯: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"


def get_deep_thinking_model() -> ChatOpenAI:
    """è·å–é…ç½®ä¸ºæ·±åº¦æ€è€ƒæ¨¡å¼çš„ ChatOpenAI æ¨¡å‹"""
    model_name = os.getenv("AGENT_MODEL", "doubao-seed-1-8-251228")
    base_url = os.getenv("AGENT_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
    api_key = os.getenv("AGENT_API_KEY")
    
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® AGENT_API_KEY ç¯å¢ƒå˜é‡")
        sys.exit(1)
    
    print(f"ğŸ“‹ æ¨¡å‹é…ç½®:")
    print(f"   - model: {model_name}")
    print(f"   - base_url: {base_url}")
    print(f"   - reasoning: enabled (effort=medium)")
    
    return ChatOpenAI(
        model=model_name,
        api_key=api_key,
        base_url=base_url,
        temperature=0.7,
        timeout=120,
        max_tokens=2000,
        reasoning={"effort": "medium"},
    )


def test_1_single_tool_call_reasoning():
    """
    æµ‹è¯•1ï¼šå•æ¬¡ tool è°ƒç”¨æ—¶ï¼Œå“åº”ä¸­æ˜¯å¦åŒ…å« reasoning å†…å®¹
    """
    print("\n" + "=" * 70)
    print("æµ‹è¯•1ï¼šå•æ¬¡ Tool è°ƒç”¨ - æ£€æŸ¥å“åº”ä¸­çš„ reasoning å†…å®¹")
    print("=" * 70)
    
    call_counter["count"] = 0
    callback = ReasoningInspectorCallback()
    model = get_deep_thinking_model()
    
    agent = create_agent(
        model=model,
        tools=[calculate_fibonacci],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹ã€‚è¯·ä½¿ç”¨æä¾›çš„å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è®¡ç®—ã€‚",
    )
    
    try:
        result = agent.invoke(
            {"messages": [HumanMessage(content="è¯·è®¡ç®—ç¬¬ 10 ä¸ªæ–æ³¢é‚£å¥‘æ•°æ˜¯å¤šå°‘ï¼Ÿ")]},
            config={"callbacks": [callback]}
        )
        
        print("\n" + "-" * 50)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
        print("-" * 50)
        print(f"   - LLM è°ƒç”¨æ¬¡æ•°: {callback.call_count}")
        print(f"   - å“åº”ä¸­å‘ç° reasoning çš„æ¬¡æ•°: {len(callback.reasoning_found_in_responses)}")
        print(f"   - Tool è°ƒç”¨æ¬¡æ•°: {call_counter['count']}")
        
        final_response = result["messages"][-1].content
        print(f"\næœ€ç»ˆå“åº”: {final_response[:200]}...")
        
        if callback.reasoning_found_in_responses:
            print("\nâœ… æµ‹è¯•é€šè¿‡ï¼šå“åº”ä¸­åŒ…å« reasoning å†…å®¹")
            return True
        else:
            print("\nâš ï¸  æµ‹è¯•è­¦å‘Šï¼šå“åº”ä¸­æœªå‘ç° reasoning å†…å®¹ï¼ˆå¯èƒ½æ¨¡å‹ä¸æ”¯æŒæˆ–æœªå¯ç”¨æ·±åº¦æ€è€ƒï¼‰")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_2_multi_tool_calls_reasoning_preservation():
    """
    æµ‹è¯•2ï¼šå¤šæ¬¡ tool è°ƒç”¨æ—¶ï¼Œå‰ä¸€è½®çš„ reasoning æ˜¯å¦è¢«ä¼ é€’åˆ°ä¸‹ä¸€è½®è¯·æ±‚
    
    è¿™æ˜¯éªŒè¯æ ¸å¿ƒçŒœæƒ³çš„å…³é”®æµ‹è¯•
    """
    print("\n" + "=" * 70)
    print("æµ‹è¯•2ï¼šå¤šè½® Tool è°ƒç”¨ - æ£€æŸ¥ reasoning æ˜¯å¦åœ¨è¯·æ±‚é—´ä¼ é€’")
    print("=" * 70)
    
    call_counter["count"] = 0
    callback = ReasoningInspectorCallback()
    model = get_deep_thinking_model()
    
    agent = create_agent(
        model=model,
        tools=[calculate_fibonacci, get_current_time],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½åŠ©æ‰‹ã€‚è¯·æŒ‰é¡ºåºå®Œæˆç”¨æˆ·çš„æ‰€æœ‰è¯·æ±‚ã€‚",
    )
    
    try:
        result = agent.invoke(
            {"messages": [HumanMessage(
                content="è¯·ä¾æ¬¡å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n"
                        "1. é¦–å…ˆè®¡ç®—ç¬¬ 5 ä¸ªæ–æ³¢é‚£å¥‘æ•°\n"
                        "2. ç„¶åè·å–å½“å‰æ—¶é—´\n"
                        "3. æœ€åè®¡ç®—ç¬¬ 8 ä¸ªæ–æ³¢é‚£å¥‘æ•°\n"
                        "è¯·ä¸€æ­¥ä¸€æ­¥æ¥ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½è¦è°ƒç”¨å·¥å…·ã€‚"
            )]},
            config={"callbacks": [callback]}
        )
        
        print("\n" + "-" * 50)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
        print("-" * 50)
        print(f"   - LLM è°ƒç”¨æ¬¡æ•°: {callback.call_count}")
        print(f"   - å“åº”ä¸­å‘ç° reasoning çš„æ¬¡æ•°: {len(callback.reasoning_found_in_responses)}")
        print(f"   - è¯·æ±‚ä¸­å‘ç° reasoning çš„æ¬¡æ•°: {len([r for r in callback.reasoning_found_in_requests if r['reasoning_blocks']])}")
        print(f"   - Tool è°ƒç”¨æ¬¡æ•°: {call_counter['count']}")
        
        reasoning_preserved = False
        for req_info in callback.reasoning_found_in_requests[1:]:
            if req_info["reasoning_blocks"]:
                reasoning_preserved = True
                print(f"\nâœ… åœ¨ç¬¬ {req_info['call_number']} æ¬¡ LLM è°ƒç”¨çš„è¯·æ±‚ä¸­å‘ç°äº†ä¹‹å‰çš„ reasoning blocks!")
                break
        
        if reasoning_preserved:
            print("\nâœ… æµ‹è¯•é€šè¿‡ï¼šreasoning å†…å®¹åœ¨å¤šè½®è°ƒç”¨é—´è¢«æ­£ç¡®ä¿ç•™å’Œä¼ é€’")
            return True
        else:
            print("\nâš ï¸  æµ‹è¯•è­¦å‘Šï¼šæœªæ£€æµ‹åˆ° reasoning åœ¨è¯·æ±‚é—´ä¼ é€’")
            print("   å¯èƒ½åŸå› :")
            print("   1. æ¨¡å‹æœªå¯ç”¨æ·±åº¦æ€è€ƒæˆ–ä¸æ”¯æŒ")
            print("   2. LangChain ç‰ˆæœ¬ä¸æ”¯æŒ reasoning ä¼ é€’")
            print("   3. ç«å±±å¼•æ“ API å“åº”æ ¼å¼ä¸ OpenAI ä¸å…¼å®¹")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_3_inspect_message_structure():
    """
    æµ‹è¯•3ï¼šè¯¦ç»†æ£€æŸ¥æ¶ˆæ¯ç»“æ„ï¼Œæ‰“å°å®Œæ•´çš„ AIMessage å†…å®¹
    """
    print("\n" + "=" * 70)
    print("æµ‹è¯•3ï¼šè¯¦ç»†æ£€æŸ¥ AIMessage ç»“æ„")
    print("=" * 70)
    
    call_counter["count"] = 0
    model = get_deep_thinking_model()
    
    agent = create_agent(
        model=model,
        tools=[calculate_fibonacci],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹ã€‚",
    )
    
    try:
        result = agent.invoke(
            {"messages": [HumanMessage(content="è®¡ç®—ç¬¬ 3 ä¸ªæ–æ³¢é‚£å¥‘æ•°")]}
        )
        
        print("\nğŸ“‹ å®Œæ•´æ¶ˆæ¯å†å²:")
        for i, msg in enumerate(result["messages"]):
            print(f"\n--- æ¶ˆæ¯ #{i} ({type(msg).__name__}) ---")
            
            if isinstance(msg, AIMessage):
                print(f"  content type: {type(msg.content)}")
                if isinstance(msg.content, str):
                    print(f"  content: {msg.content[:200]}...")
                elif isinstance(msg.content, list):
                    print(f"  content blocks ({len(msg.content)}):")
                    for j, block in enumerate(msg.content):
                        if isinstance(block, dict):
                            block_type = block.get("type", "unknown")
                            print(f"    [{j}] type={block_type}")
                            if block_type == "reasoning":
                                summary = block.get("summary", [])
                                print(f"        summary items: {len(summary)}")
                                for s in summary[:2]:
                                    if isinstance(s, dict):
                                        text = s.get("text", "")[:80]
                                        print(f"        - {text}...")
                            elif block_type == "text":
                                text = block.get("text", "")[:80]
                                print(f"        text: {text}...")
                        else:
                            print(f"    [{j}] {str(block)[:80]}...")
                
                print(f"  additional_kwargs keys: {list(msg.additional_kwargs.keys())}")
                if "reasoning" in msg.additional_kwargs:
                    print(f"  âœ… additional_kwargs ä¸­åŒ…å« 'reasoning'")
                    reasoning = msg.additional_kwargs["reasoning"]
                    if isinstance(reasoning, dict):
                        print(f"     reasoning keys: {list(reasoning.keys())}")
                
                print(f"  tool_calls: {len(msg.tool_calls)} ä¸ª")
                for tc in msg.tool_calls:
                    print(f"    - {tc['name']}({tc['args']})")
                
                print(f"  response_metadata keys: {list(msg.response_metadata.keys()) if msg.response_metadata else 'None'}")
            
            elif isinstance(msg, ToolMessage):
                print(f"  tool_call_id: {msg.tool_call_id}")
                print(f"  content: {str(msg.content)[:100]}...")
            
            elif isinstance(msg, HumanMessage):
                print(f"  content: {str(msg.content)[:100]}...")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_4_direct_model_invocation():
    """
    æµ‹è¯•4ï¼šç›´æ¥è°ƒç”¨æ¨¡å‹ï¼ˆä¸é€šè¿‡ agentï¼‰ï¼Œæ£€æŸ¥åŸå§‹å“åº”ä¸­çš„ reasoning
    """
    print("\n" + "=" * 70)
    print("æµ‹è¯•4ï¼šç›´æ¥è°ƒç”¨æ¨¡å‹ - æ£€æŸ¥åŸå§‹å“åº”ä¸­çš„ reasoning")
    print("=" * 70)
    
    model = get_deep_thinking_model()
    
    try:
        response = model.invoke([
            HumanMessage(content="ç®€å•è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯æ–æ³¢é‚£å¥‘æ•°åˆ—ï¼Œç”¨ä¸€å¥è¯å›ç­”ã€‚")
        ])
        
        print(f"\nğŸ“‹ æ¨¡å‹å“åº”è¯¦æƒ…:")
        print(f"  - å“åº”ç±»å‹: {type(response).__name__}")
        print(f"  - content type: {type(response.content)}")
        
        if isinstance(response.content, str):
            print(f"  - content: {response.content[:200]}...")
        elif isinstance(response.content, list):
            print(f"  - content blocks: {len(response.content)}")
            for i, block in enumerate(response.content):
                if isinstance(block, dict):
                    print(f"    [{i}] type={block.get('type', 'unknown')}")
        
        print(f"\n  - additional_kwargs: {list(response.additional_kwargs.keys())}")
        
        if "reasoning" in response.additional_kwargs:
            print("  âœ… å‘ç° reasoning åœ¨ additional_kwargs ä¸­")
            reasoning = response.additional_kwargs["reasoning"]
            print(f"     reasoning type: {type(reasoning)}")
            if isinstance(reasoning, dict):
                print(f"     reasoning keys: {list(reasoning.keys())}")
                summary = reasoning.get("summary", [])
                print(f"     summary items: {len(summary)}")
                for s in summary[:3]:
                    if isinstance(s, dict):
                        text = s.get("text", "")[:100]
                        print(f"       - {text}...")
            return True
        else:
            print("  âš ï¸  additional_kwargs ä¸­æ²¡æœ‰ reasoning")
            
            has_reasoning_in_content = False
            if isinstance(response.content, list):
                for block in response.content:
                    if isinstance(block, dict) and block.get("type") == "reasoning":
                        has_reasoning_in_content = True
                        print("  âœ… å‘ç° reasoning åœ¨ content blocks ä¸­")
                        break
            
            return has_reasoning_in_content
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_5_inspect_actual_api_payload():
    """
    æµ‹è¯•5ï¼šæ£€æŸ¥å®é™…å‘é€ç»™ API çš„ payload ä¸­æ˜¯å¦åŒ…å« reasoning
    
    é€šè¿‡ monkey patch _get_request_payload æ¥æ•è·å®é™…å‘é€çš„è¯·æ±‚
    """
    print("\n" + "=" * 70)
    print("æµ‹è¯•5ï¼šæ£€æŸ¥å®é™…å‘é€ç»™ API çš„ payloadï¼ˆå…³é”®æµ‹è¯•ï¼‰")
    print("=" * 70)
    
    call_counter["count"] = 0
    model = get_deep_thinking_model()
    
    captured_payloads = []
    original_get_request_payload = model._get_request_payload
    
    def patched_get_request_payload(messages, **kwargs):
        payload = original_get_request_payload(messages, **kwargs)
        captured_payloads.append({
            "call_number": len(captured_payloads) + 1,
            "input": payload.get("input", []),
            "messages_count": len(messages)
        })
        return payload
    
    model._get_request_payload = patched_get_request_payload
    
    agent = create_agent(
        model=model,
        tools=[calculate_fibonacci, get_current_time],
        system_prompt="ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚",
    )
    
    try:
        result = agent.invoke(
            {"messages": [HumanMessage(content="å…ˆè®¡ç®—ç¬¬ 3 ä¸ªæ–æ³¢é‚£å¥‘æ•°ï¼Œå†è·å–å½“å‰æ—¶é—´")]}
        )
        
        print(f"\nğŸ“‹ æ•è·åˆ° {len(captured_payloads)} æ¬¡ API è°ƒç”¨çš„ payload:")
        
        reasoning_in_payload = False
        for payload_info in captured_payloads:
            call_num = payload_info["call_number"]
            input_items = payload_info["input"]
            
            print(f"\n--- ç¬¬ {call_num} æ¬¡è°ƒç”¨ ---")
            print(f"  input items æ•°é‡: {len(input_items)}")
            
            for i, item in enumerate(input_items):
                item_type = item.get("type", "unknown")
                print(f"  [{i}] type={item_type}")
                
                if item_type == "reasoning":
                    reasoning_in_payload = True
                    print(f"      âœ… å‘ç° reasoning item!")
                    summary = item.get("summary", [])
                    if summary:
                        for s in summary[:2]:
                            if isinstance(s, dict):
                                text = s.get("text", "")[:80]
                                print(f"         - {text}...")
                elif item_type == "message":
                    role = item.get("role", "")
                    content = item.get("content", [])
                    print(f"      role={role}, content blocks={len(content) if isinstance(content, list) else 'str'}")
                    if isinstance(content, list):
                        for j, block in enumerate(content):
                            if isinstance(block, dict):
                                block_type = block.get("type", "unknown")
                                print(f"        [{j}] type={block_type}")
                elif item_type == "function_call":
                    name = item.get("name", "")
                    print(f"      name={name}")
                elif item_type == "function_call_output":
                    output = str(item.get("output", ""))[:50]
                    print(f"      output={output}...")
        
        if reasoning_in_payload:
            print("\nâœ… æµ‹è¯•é€šè¿‡ï¼šreasoning åœ¨åç»­è¯·æ±‚çš„ payload ä¸­è¢«æ­£ç¡®ä¼ é€’!")
            return True
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼šreasoning æ²¡æœ‰åœ¨åç»­è¯·æ±‚çš„ payload ä¸­å‡ºç°")
            print("   è¿™æ„å‘³ç€æ·±åº¦æ€è€ƒå†…å®¹åœ¨ tool è°ƒç”¨å¾ªç¯ä¸­ä¸¢å¤±äº†ï¼")
            return False
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        model._get_request_payload = original_get_request_payload


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "ğŸš€" * 30)
    print("æ·±åº¦æ€è€ƒå†…å®¹ï¼ˆReasoning Contentï¼‰ä¿ç•™æµ‹è¯•")
    print("ğŸš€" * 30)
    
    results = {}
    
    results["test_4_direct_model"] = test_4_direct_model_invocation()
    
    results["test_3_message_structure"] = test_3_inspect_message_structure()
    
    results["test_1_single_call"] = test_1_single_tool_call_reasoning()
    
    results["test_2_multi_calls"] = test_2_multi_tool_calls_reasoning_preservation()
    
    results["test_5_actual_payload"] = test_5_inspect_actual_api_payload()
    
    print("\n" + "=" * 70)
    print("ğŸ“Š æœ€ç»ˆæµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 70)
    for test_name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥/è­¦å‘Š"
        print(f"  {test_name}: {status}")
    
    all_passed = all(results.values())
    print("\n" + ("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼" if all_passed else "âš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†è¾“å‡º"))
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
