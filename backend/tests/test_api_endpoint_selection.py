"""
æµ‹è¯• LangChain æ ¹æ® reasoning å‚æ•°è‡ªåŠ¨é€‰æ‹© API ç«¯ç‚¹

ç›®çš„ï¼šéªŒè¯ LangChain æ˜¯å¦çœŸçš„ä¼šæ ¹æ® reasoning å‚æ•°è‡ªåŠ¨é€‰æ‹© Responses API
"""
import os
from unittest.mock import patch, MagicMock

from dotenv import load_dotenv
load_dotenv()

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage


def test_api_endpoint_selection():
    """æµ‹è¯• API ç«¯ç‚¹è‡ªåŠ¨é€‰æ‹©"""
    
    print("\n" + "=" * 70)
    print("æµ‹è¯•ï¼šLangChain API ç«¯ç‚¹è‡ªåŠ¨é€‰æ‹©")
    print("=" * 70)
    
    base_url = os.getenv('AGENT_BASE_URL', 'https://ark-cn-beijing.bytedance.net/api/v3')
    api_key = os.getenv('AGENT_API_KEY')
    model_name = os.getenv('AGENT_MODEL')
    
    print(f"\né…ç½®ï¼š")
    print(f"  base_url: {base_url}")
    print(f"  model: {model_name}")
    
    print("\n--- æµ‹è¯•1ï¼šä¸å¯ç”¨ reasoning ---")
    model_no_reasoning = ChatOpenAI(
        model=model_name,
        api_key=api_key,
        base_url=base_url,
        temperature=0.0,
        reasoning=None,
    )
    
    result1 = model_no_reasoning._use_responses_api({})
    print(f"  _use_responses_api() = {result1}")
    print(f"  é¢„æœŸä½¿ç”¨: {'Responses API' if result1 else 'Chat Completions API'}")
    
    print("\n--- æµ‹è¯•2ï¼šå¯ç”¨ reasoning ---")
    model_with_reasoning = ChatOpenAI(
        model=model_name,
        api_key=api_key,
        base_url=base_url,
        temperature=0.0,
        reasoning={"effort": "medium"},
    )
    
    result2 = model_with_reasoning._use_responses_api({})
    print(f"  _use_responses_api() = {result2}")
    print(f"  é¢„æœŸä½¿ç”¨: {'Responses API' if result2 else 'Chat Completions API'}")
    
    print("\n--- æµ‹è¯•3ï¼šå®é™… API è°ƒç”¨éªŒè¯ ---")
    
    captured_calls = {"chat_completions": 0, "responses": 0}
    
    original_chat_create = model_no_reasoning.root_client.chat.completions.create
    original_responses_create = model_no_reasoning.root_client.responses.create
    
    def mock_chat_create(*args, **kwargs):
        captured_calls["chat_completions"] += 1
        print(f"  ğŸ“¡ è°ƒç”¨äº† Chat Completions API!")
        return original_chat_create(*args, **kwargs)
    
    def mock_responses_create(*args, **kwargs):
        captured_calls["responses"] += 1
        print(f"  ğŸ“¡ è°ƒç”¨äº† Responses API!")
        return original_responses_create(*args, **kwargs)
    
    print("\n  3a. æµ‹è¯•æ—  reasoning çš„æ¨¡å‹:")
    try:
        model_no_reasoning.root_client.chat.completions.create = mock_chat_create
        model_no_reasoning.root_client.responses.create = mock_responses_create
        
        response = model_no_reasoning.invoke([HumanMessage(content="è¯´'æµ‹è¯•'")])
        print(f"     å“åº”: {response.content[:50]}...")
    except Exception as e:
        print(f"     é”™è¯¯: {e}")
    
    captured_calls = {"chat_completions": 0, "responses": 0}
    
    print("\n  3b. æµ‹è¯•æœ‰ reasoning çš„æ¨¡å‹:")
    try:
        model_with_reasoning.root_client.chat.completions.create = mock_chat_create
        model_with_reasoning.root_client.responses.create = mock_responses_create
        
        response = model_with_reasoning.invoke([HumanMessage(content="è¯´'æµ‹è¯•'")])
        print(f"     å“åº”: {response.content[:50] if isinstance(response.content, str) else str(response.content)[:50]}...")
    except Exception as e:
        print(f"     é”™è¯¯: {e}")
    
    print("\n" + "=" * 70)
    print("ç»“è®ºï¼š")
    print("=" * 70)
    print(f"  - æ—  reasoning æ—¶ _use_responses_api(): {result1}")
    print(f"  - æœ‰ reasoning æ—¶ _use_responses_api(): {result2}")
    
    if not result1 and result2:
        print("\nâœ… éªŒè¯æˆåŠŸï¼šLangChain ä¼šæ ¹æ® reasoning å‚æ•°è‡ªåŠ¨é€‰æ‹© API ç«¯ç‚¹")
        print("   - reasoning=None â†’ Chat Completions API")
        print("   - reasoning={'effort': '...'} â†’ Responses API")
        return True
    else:
        print("\nâŒ éªŒè¯å¤±è´¥ï¼šè¡Œä¸ºä¸é¢„æœŸä¸ç¬¦")
        return False


if __name__ == "__main__":
    test_api_endpoint_selection()
