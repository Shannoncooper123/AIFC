支持视觉理解的大模型当前支持在请求中传入图片链接，图片信息需作为用户角色输入信息传给大模型，即"role": "user"。
import os
# Install SDK:  pip install 'volcengine-python-sdk[ark]'
from volcenginesdkarkruntime import Ark 

client = Ark(
    # The base URL for model invocation
    base_url="https://ark-cn-beijing.bytedance.net/api/v3", 
    # Get API Key：https://cloud.bytedance.net/ark/region:ark+cn-beijing/apikey
    api_key=os.getenv('ARK_API_KEY'), 
)

completion = client.chat.completions.create(
    # Replace with your Endpoint ID
    model = "<Endpoint_ID>",
    messages = [
        {
            "role": "user",  
            "content": [   
                # 图片信息，希望模型理解的图片
                {"type": "image_url", "image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"},},
                # 文本消息，希望模型根据图片信息回答的问题
                {"type": "text", "text": "支持输入图片的模型系列是哪个？"}, 
            ],
        }
    ],
)

print(completion.choices[0].message.content)
使用说明
处理完图片/视频后，文件会从方舟服务器删除。方舟不会保留你提交的图片、视频以及文本信息等用户数据来训练模型。

图片理解
图片传入方式
图片 URL 或 Base64 编码。用图片 URL 方式时，需确保图片 URL 可被访问。
如果你希望获得更低的时延和成本，建议使用TOS（火山引擎对象存储）存储图片并生成访问链接。方舟与 TOS 网络打通，可使用内网通信，具备好处：
高速访问图片速度，降低模型回复的时延。
降低公网访问图片产生的流量费用。

Chat API 是无状态的，如需模型对同一张图片进行多轮理解，则每次请求时都需传入该图片信息。
图片像素说明
方舟在处理图片前会先行进行图片尺寸判断，如果图片超出下面的限制，会直接报错，传入图片满足下面条件（单位 px）：
宽 > 14 且 高>14。
宽*高范围： [196, 36,000,000]。
满足上述条件的图片，方舟检测图片大小并将图片等比例压缩，并根据不同模式，将图片像素处理（等比例）至下面范围。
detail:low模式下，104万（1024×1024） px。
detail:high模式下，401万（2048×1960） px。
其中，detail 字段控制理解图像精度，具体请参见
对图片预处理，如裁剪/压缩图片，控制图片像素（宽×高）在104万（low）/ 401万（high）内，可降低模型响应时延与 token 消耗。
图片文件容量
单张图片小于 10 MB。
使用 base64 编码，请求体不可超过 64 MB。
token 用量说明
token 用量，根据图片宽高像素计算可得。图片转化 token 的公式为：
min(image_width * image_hight ÷ 784, max_image_tokens)

detail:high模式下，单图 token 限制(max_image_tokens)为 5120 token。
detail:low模式下，单图 token 限制(max_image_tokens)为 1312 token。
×图片尺寸为 1280 px × 720 px，即宽为 1280 px，高为 720 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为1280×720÷784=1176，因为小于 1312，消耗 token 数为 1176 。
×图片尺寸为 1920 px × 1080 px，即宽为 1920 px，高为 1080 px，传入模型图片 token 限制为 1312，则理解这张图消耗的 token 为1920×1080÷784=2645，因为大于 1312，消耗 token 数为 1312 。这时会压缩 token，即图片的细节会丢失部分，譬如字体很小的图片，模型可能就无法准确识别文字内容。
图片格式说明
支持的图片格式如下表，注意文件后缀匹配图片格式，即图片文件扩展名（URL传入时）、图片格式声明（Base64 编码传入时）需与图片实际信息一致。
多图输入
API 可支持接受和处理多个图像输入，这些图像可通过图片可访问 URL 或图片转为 Base64 编码后输入，模型将结合所有传入的图像中的信息来
import os
# Install SDK:  pip install 'volcengine-python-sdk[ark]'
from volcenginesdkarkruntime import Ark 

client = Ark(
    # The base URL for model invocation
    base_url="https://ark-cn-beijing.bytedance.net/api/v3", 
    # Get API Key：https://cloud.bytedance.net/ark/region:ark+cn-beijing/apikey
    api_key=os.getenv('ARK_API_KEY'), 
)

completion = client.chat.completions.create(
    # Replace with your Endpoint ID
    model = "<Endpoint_ID>",
    messages=[
        {
            "role": "user",
            "content": [                
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_1.png"}},
                {"type": "image_url","image_url": {"url":  "https://ark-project.tos-cn-beijing.volces.com/doc_image/ark_demo_img_2.png"}},
                {"type": "text", "text": "支持输入图片的模型系列是哪个？同时，豆包应用场景有哪些？"},
            ],
        }
    ],
)

print(completion.choices[0])
传入 Base64 编码格式时，请遵循以下规则：
格式遵循 data:image/<IMAGE_FORMAT>;base64,<BASE64_ENCODING>，其中，
图片格式：jpeg、png、gif等，支持的图片格式详细见图片格式说明。
Base64 编码：图片的 Base64 编码。
import base64
import os
# Install SDK:  pip install 'volcengine-python-sdk[ark]'
from volcenginesdkarkruntime import Ark 

client = Ark(
    # The base URL for model invocation
    base_url="https://ark-cn-beijing.bytedance.net/api/v3", 
    # Get API Key：https://cloud.bytedance.net/ark/region:ark+cn-beijing/apikey
    api_key=os.getenv('ARK_API_KEY'), 
)

# 定义方法将指定路径图片转为Base64编码
def encode_image(image_path):
  with open(image_path, "rb") as image_file:
    return base64.b64encode(image_file.read()).decode('utf-8')

# 需传给大模型的图片
image_path = "path_to_your_image.jpg"

# 将图片转为Base64编码
base64_image = encode_image(image_path)

completion = client.chat.completions.create(
  # Replace with your Endpoint ID
  model = "<Endpoint_ID>",
  messages=[
    {
      "role": "user",
      "content": [
        {
          "type": "image_url",
          "image_url": {
          # 需注意：传入Base64编码遵循格式 data:image/<IMAGE_FORMAT>;base64,{base64_image}：
          # PNG图片："url":  f"data:image/png;base64,{base64_image}"
          # JPEG图片："url":  f"data:image/jpeg;base64,{base64_image}"
          # WEBP图片："url":  f"data:image/webp;base64,{base64_image}"
            "url":  f"data:image/<IMAGE_FORMAT>;base64,{base64_image}"
          },         
        },
        {
          "type": "text",
          "text": "图里有什么",
        },
      ],
    }
  ],
)

print(completion.choices[0])
控制图片理解的精细度
控制图片理解的精细度（指对画面的精细）： image_pixel_limit 、detail 字段，2个字段若同时配置，则生效逻辑如下：
生效前提：图片像素范围在 [196, 36,000,000] px，否则直接报错。
生效优先级：image_pixel_limit 高于 detail 字段，即同时配置 detail 与 image_pixel_limit 字段时，生效 image_pixel_limit 字段配置。
缺省时生效：image_pixel_limit 字段的 min_pixels / max_pixels 字段未设置，则使用 detail （默认值为low）配置所对应的值。
detail为low：min_pixels 值3136 ；max_pixels 值1048576。
detail为high：min_pixels 值3136 ；max_pixels 值4014080。
下面分别介绍如何通过 detail 、 image_pixel_limit 控制视觉理解的精度。
通过 detail 字段（图片理解）
你可通过detail参数来控制模型理解图片的精细度，返回速度，token用量，计费公式请参见token 用量说明。
low：“低分辨率”模式，默认此模式，处理速度会提高，适合图片本身细节较少或者只需模型理解图片大致信息或者对速度有要求的场景。此时 min_pixels 取值3136、max_pixels 取值1048576。不在此范围且小于3600w px的图片，方舟会等比例缩放至范围内。
high：“高分辨率”模式，模型可感知图片更多的细节，但是处理图片速度会降低，适合图像像素值高且需关注细节信息的场景，如街道地图分析等。此时 min_pixels 取值3136、max_pixels 取值4014080。不在此范围且小于3600w px的图片，方舟会等比例缩放至范围内。
