"""ç›‘æŽ§æ•°æ®æŽ¨é€æœåŠ¡ï¼štrade_state å®šæ—¶æŽ¨é€ï¼Œagent_reports/position_history æŒ‰æ–‡ä»¶å˜åŒ–æŽ¨é€"""
import os
import sys
import time
import signal
import json
import threading
from typing import Dict, Any
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, BASE_DIR)

# åŠ è½½ .env æ–‡ä»¶
load_dotenv(os.path.join(BASE_DIR, '.env'))

from web_dashboard.file_watcher import FileWatcher
from web_dashboard.faas_pusher import FaaSPusher
from web_dashboard.asset_tracker import AssetTracker
from monitor_module.utils.logger import setup_logger

logger = setup_logger()

# å…¨å±€å˜é‡
file_watcher = None
faas_pusher = None
asset_tracker = None
running = True
timer_thread = None
asset_thread = None

# ç›‘æŽ§æ–‡ä»¶è·¯å¾„
WATCHED_FILES = {
    'trade_state': os.path.join(BASE_DIR, 'agent', 'trade_state.json'),
    'position_history': os.path.join(BASE_DIR, 'logs', 'position_history.json'),
    'agent_reports': os.path.join(BASE_DIR, 'logs', 'agent_reports.json'),
    'pending_orders': os.path.join(BASE_DIR, 'agent', 'pending_orders.json'),
    'asset_timeline': os.path.join(BASE_DIR, 'logs', 'asset_timeline.json'),
}


def read_json_file(file_path: str) -> Dict[str, Any]:
    """è¯»å–JSONï¼ˆå¸¦é‡è¯•ï¼‰ï¼›å¤±è´¥è¿”å›ž None"""
    max_retries = 3
    retry_delay = 0.1
    
    for attempt in range(max_retries):
        try:
            if attempt > 0:
                time.sleep(retry_delay * attempt)
            
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except json.JSONDecodeError:
            if attempt < max_retries - 1:
                continue
            else:
                return None
        except FileNotFoundError:
            return None
        except Exception as e:
            logger.error(f'âœ— è¯»å–æ–‡ä»¶é”™è¯¯ {file_path}: {e}')
            return None
    
    return None


def push_data_to_faas(file_type: str, data: Dict[str, Any]):
    """æŽ¨é€æ•°æ®åˆ° FaaS"""
    if faas_pusher and faas_pusher.enabled and data:
        try:
            success = faas_pusher.push_data(file_type, data)
            if not success:
                logger.error(f'âœ— æŽ¨é€ {file_type} åˆ° FaaS å¤±è´¥')
        except Exception as e:
            logger.error(f'âœ— æŽ¨é€ {file_type} æ—¶å‘ç”Ÿé”™è¯¯: {e}')


def unified_push_worker():
    """æ¯ 10 ç§’ç»Ÿä¸€æŽ¨é€ä¸€æ¬¡æ‰€æœ‰ç±»åž‹æ•°æ®ï¼ˆtrade_stateã€position_historyã€agent_reportsã€pending_ordersã€asset_timelineï¼‰"""
    global running

    logger.info("â° ç»Ÿä¸€å®šæ—¶æŽ¨é€çº¿ç¨‹å·²å¯åŠ¨ï¼ˆé—´éš”: 10ç§’ï¼Œç±»åž‹: trade_state/position_history/agent_reports/pending_orders/asset_timelineï¼‰")

    data_types = ['trade_state', 'position_history', 'agent_reports', 'pending_orders', 'asset_timeline']

    while running:
        try:
            for dt in data_types:
                data = read_json_file(WATCHED_FILES[dt])
                if data:
                    push_data_to_faas(dt, data)
        except Exception as e:
            logger.error(f'âœ— ç»Ÿä¸€å®šæ—¶æŽ¨é€é”™è¯¯: {e}')

        # ç­‰å¾…10ç§’
        for _ in range(100):  # åˆ†æˆ100æ¬¡æ£€æŸ¥ï¼Œæ¯æ¬¡0.1ç§’ï¼Œæ–¹ä¾¿å¿«é€Ÿé€€å‡º
            if not running:
                break
            time.sleep(0.1)

    logger.info("â° ç»Ÿä¸€å®šæ—¶æŽ¨é€çº¿ç¨‹å·²åœæ­¢")


def asset_tracking_worker():
    """æ¯10åˆ†é’Ÿè®°å½•ä¸€æ¬¡èµ„äº§å¿«ç…§"""
    global running, asset_tracker
    
    logger.info("ðŸ“Š èµ„äº§æ‰“ç‚¹çº¿ç¨‹å·²å¯åŠ¨ï¼ˆé—´éš”: 10åˆ†é’Ÿï¼‰")
    
    while running:
        try:
            # è¯»å– trade_state
            trade_state_data = read_json_file(WATCHED_FILES['trade_state'])
            if trade_state_data and asset_tracker:
                # è®°å½•èµ„äº§å¿«ç…§
                success = asset_tracker.record_snapshot(trade_state_data)
                if success:
                    # è¯»å–å¹¶æŽ¨é€æ›´æ–°åŽçš„ asset_timeline
                    asset_timeline_data = read_json_file(WATCHED_FILES['asset_timeline'])
                    if asset_timeline_data:
                        push_data_to_faas('asset_timeline', asset_timeline_data)
        
        except Exception as e:
            logger.error(f'âœ— èµ„äº§æ‰“ç‚¹é”™è¯¯: {e}')
        
        # ç­‰å¾…10åˆ†é’Ÿï¼ˆ600ç§’ï¼‰
        for _ in range(6000):  # åˆ†æˆ6000æ¬¡æ£€æŸ¥ï¼Œæ¯æ¬¡0.1ç§’ï¼Œæ–¹ä¾¿å¿«é€Ÿé€€å‡º
            if not running:
                break
            time.sleep(0.1)
    
    logger.info("ðŸ“Š èµ„äº§æ‰“ç‚¹çº¿ç¨‹å·²åœæ­¢")


def handle_file_update(file_type: str, data: Dict[str, Any]):
    """æ–‡ä»¶å˜åŒ–æ—¶çš„å¤„ç†ï¼šç»Ÿä¸€èŠ‚æ‹å™¨æž¶æž„ä¸‹ä¸å†ç«‹å³æŽ¨é€ï¼Œä»…è®°å½•æ£€æµ‹æ—¥å¿—ï¼ˆä¿ç•™æ‰©å±•å¯èƒ½ï¼‰"""
    logger.info(f'ðŸ“ æ£€æµ‹åˆ° {file_type} å˜åŒ–ï¼ˆç»Ÿä¸€å®šæ—¶æŽ¨é€æž¶æž„ï¼šä¸åšç«‹å³æŽ¨é€ï¼‰')
    # ç»Ÿä¸€æž¶æž„ä¸‹ï¼ŒæŽ¨é€ç”± unified_push_worker æ¯ 10 ç§’æ‰§è¡Œä¸€æ¬¡ã€‚


def signal_handler(sig, frame):
    """ä¼˜é›…é€€å‡º"""
    global running, timer_thread, asset_thread
    logger.info('\n\næ­£åœ¨å…³é—­æœåŠ¡...')
    running = False
    
    # ç­‰å¾…å®šæ—¶æŽ¨é€çº¿ç¨‹ç»“æŸ
    if timer_thread and timer_thread.is_alive():
        logger.info('ç­‰å¾…å®šæ—¶æŽ¨é€çº¿ç¨‹ç»“æŸ...')
        timer_thread.join(timeout=2)
    
    # ç­‰å¾…èµ„äº§æ‰“ç‚¹çº¿ç¨‹ç»“æŸ
    if asset_thread and asset_thread.is_alive():
        logger.info('ç­‰å¾…èµ„äº§æ‰“ç‚¹çº¿ç¨‹ç»“æŸ...')
        asset_thread.join(timeout=2)
    
    if file_watcher:
        file_watcher.stop()
    
    logger.info('æœåŠ¡å·²å…³é—­')
    sys.exit(0)


def start_pusher_service(faas_url: str = None):
    """å¯åŠ¨æœåŠ¡"""
    global file_watcher, faas_pusher, asset_tracker, running, timer_thread, asset_thread
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    logger.info("=" * 70)
    logger.info("ç›‘æŽ§æ•°æ®æŽ¨é€æœåŠ¡")
    logger.info("=" * 70)
    
    # ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å–é…ç½®
    if faas_url is None:
        faas_url = os.environ.get('FAAS_URL')
        if not faas_url:
            logger.error("âœ— é”™è¯¯: æœªè®¾ç½® FAAS_URL çŽ¯å¢ƒå˜é‡")
            logger.error("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®: FAAS_URL=your_faas_url")
            sys.exit(1)
    
    # åˆ›å»ºæ–‡ä»¶ç›‘æŽ§å™¨ï¼ˆç”¨äºŽ position_historyã€agent_reportsã€pending_ordersã€asset_timelineï¼‰
    file_watcher = FileWatcher(BASE_DIR)
    # æ³¨ï¼šç»Ÿä¸€èŠ‚æ‹å™¨æž¶æž„ä¸‹ï¼Œæ–‡ä»¶ç›‘æŽ§å™¨å¯ç”¨äºŽæœªæ¥æ‰©å±•ï¼Œä½†å½“å‰ä¸æ³¨å†Œå›žè°ƒä¸Žä¸å¯åŠ¨è§‚å¯Ÿè€…ï¼Œé¿å…å˜åŒ–ç«‹æŽ¨ã€‚

    # åˆ›å»ºèµ„äº§æ‰“ç‚¹è®°å½•å™¨
    asset_tracker = AssetTracker(
        timeline_file=WATCHED_FILES['asset_timeline'],
        max_days=7  # ä¿ç•™æœ€è¿‘7å¤©æ•°æ®
    )

    # åˆ›å»ºFaaSæŽ¨é€å™¨
    if faas_url:
        faas_pusher = FaaSPusher(faas_url, timeout=10, retry_times=3)
        logger.info(f"FaaS æŽ¨é€å·²å¯ç”¨: {faas_url}")
        
        # æµ‹è¯•è¿žæŽ¥
        logger.info("\næµ‹è¯• FaaS è¿žæŽ¥...")
        if faas_pusher.test_connection():
            logger.info("âœ“ FaaS è¿žæŽ¥æµ‹è¯•æˆåŠŸ")
            # æŽ¨é€åˆå§‹æ•°æ®
            logger.info("\næŽ¨é€åˆå§‹æ•°æ®åˆ° FaaS...")
            for data_type in ['trade_state', 'position_history', 'agent_reports', 'pending_orders', 'asset_timeline']:
                data = read_json_file(WATCHED_FILES[data_type])
                if data:
                    success = faas_pusher.push_data(data_type, data)
                    if success:
                        logger.info(f"âœ“ æˆåŠŸæŽ¨é€åˆå§‹æ•°æ®: {data_type}")
                    else:
                        logger.error(f"âœ— æŽ¨é€åˆå§‹æ•°æ®å¤±è´¥: {data_type}")
        else:
            logger.error("âœ— FaaS è¿žæŽ¥æµ‹è¯•å¤±è´¥ï¼ŒæŽ¨é€åŠŸèƒ½å°†è¢«ç¦ç”¨")
            faas_pusher.disable()

    # ç»Ÿä¸€èŠ‚æ‹å™¨æž¶æž„ï¼šä¸æ³¨å†Œæ–‡ä»¶å˜åŒ–å›žè°ƒã€ä¸å¯åŠ¨æ–‡ä»¶ç›‘æŽ§å™¨ï¼Œæ‰€æœ‰ç±»åž‹ç»Ÿä¸€èµ° 10 ç§’å®šæ—¶æŽ¨é€
    # file_watcher.register_callback(handle_file_update)  # ç¦ç”¨
    # file_watcher.start()  # ç¦ç”¨

    # å¯åŠ¨ç»Ÿä¸€å®šæ—¶æŽ¨é€çº¿ç¨‹ï¼ˆæ‰€æœ‰ç±»åž‹ï¼‰
    if faas_pusher and faas_pusher.enabled:
        timer_thread = threading.Thread(target=unified_push_worker, daemon=True)
        timer_thread.start()

    # å¯åŠ¨èµ„äº§æ‰“ç‚¹çº¿ç¨‹ï¼ˆä¿ç•™åŽŸæœ‰æ¯ 10 åˆ†é’Ÿå¿«ç…§ä¸ŽæŽ¨é€ï¼‰
    asset_thread = threading.Thread(target=asset_tracking_worker, daemon=True)
    asset_thread.start()

    logger.info("=" * 70)
    logger.info("æœåŠ¡çŠ¶æ€:")
    logger.info(f"  - æ–‡ä»¶ç›‘æŽ§: âœ— å·²ç¦ç”¨ï¼ˆç»Ÿä¸€å®šæ—¶æŽ¨é€æž¶æž„ï¼‰")
    logger.info(f"  - å®šæ—¶æŽ¨é€: âœ“ è¿è¡Œä¸­ï¼ˆæ‰€æœ‰ç±»åž‹ï¼Œé—´éš” 10ç§’ï¼‰")
    logger.info(f"  - èµ„äº§æ‰“ç‚¹: âœ“ è¿è¡Œä¸­ï¼ˆasset_timelineï¼Œé—´éš” 10åˆ†é’Ÿï¼‰")
    logger.info(f"  - FaaS æŽ¨é€: âœ“ å·²å¯ç”¨")
    logger.info(f"  - FaaS åœ°å€: {faas_url}")
    logger.info("=" * 70)
    logger.info("\nç›‘æŽ§ä¸­... (æŒ‰ Ctrl+C é€€å‡º)\n")

    # ä¿æŒè¿è¡Œ
    try:
        while running:
            time.sleep(1)
    except KeyboardInterrupt:
        signal_handler(None, None)


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='ç›‘æŽ§æ•°æ®æŽ¨é€æœåŠ¡')
    parser.add_argument(
        '--faas-url',
        default=None,
        help='FaaSæœåŠ¡åœ°å€ (é»˜è®¤: ä»ŽçŽ¯å¢ƒå˜é‡FAAS_URLè¯»å–)'
    )
    
    args = parser.parse_args()
    
    start_pusher_service(faas_url=args.faas_url)
